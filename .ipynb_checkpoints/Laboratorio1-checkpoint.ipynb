{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Inteligencia de Negocios\n",
    "\n",
    "###Integrantes:\n",
    "    Juan Diego Cardona 201819447\n",
    "    Nicolas Ortega XXXXX\n",
    "    Camila Teran 201822000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio y Perfilamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un análisis exploratorio y perfilamiento de datos que le permita entenderlos, al igual que identificar el nivel de calidad de los datos y las tareas de transformación que se requieren para construir modelos de clasificación utilizando técnicas como KNN y árboles de decisión entre otras.\n",
    "Adicionalmente, la entidad desea incluir como entregable, tableros de control para apoyar tareas de entendimiento de datos y nivel de calidad de los mismos, para lo cual sugiere mostrar estadisticas tales como cantidad de columnas, cantidad de datos, valores nulos, promedio de cada variable entre otros posibles datos que puedan proveer información útil a SaludAlpes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importación de librerías \n",
    "\n",
    "En las siguientes líneas de código se importan las librerías y herramientas necesarias para desarrollar el caso de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para manejo de datos\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 25) # Número máximo de columnas a mostrar\n",
    "pd.set_option('display.max_rows', 50) # Numero máximo de filas a mostar\n",
    "import numpy as np\n",
    "np.random.seed(3301)\n",
    "import pandas as pd\n",
    "# Para preparar los datos\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Para crear el arbol de decisión \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "# Para realizar la separación del conjunto de aprendizaje en entrenamiento y test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Para evaluar el modelo\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "# Para búsqueda de hiperparámetros\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Para la validación cruzada\n",
    "from sklearn.model_selection import KFold \n",
    "#Librerías para la visualización\n",
    "import matplotlib as mplt\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import seaborn as sns \n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Carga de los datos\n",
    "A través de la librería **pandas** podemos realizar la carga de datos desde diferentes fuentes de información, en este caso se realizará la carga de un archivo plano csv (archivo separado por comas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.__version__\n",
    "mplt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos. \n",
    "df_tracks=pd.read_csv('PrepTracks.csv', sep=',', encoding = 'utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos y número de variables\n",
    "df_tracks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los datos\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver los tipos de todas la variables.\n",
    "df_tracks.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y hacer una descripción de los datos\n",
    "df_tracks.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12,8))\n",
    "ax = sns.boxplot(x=\"popularity\", data=df_tracks, orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa que hay ausencias, en particular en la variable \"decibel_range\". Veamos cuantas, para todas las variables:\n",
    "df_tracks.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justificación de preprocesamiento y limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a ejecutar los pasos de limpieza de los datos, relacionados el tratamiento de ausencias y registros duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es recomendable que todos los pasos de limpieza y preparación se realicen sobre otro archivo.\n",
    "df_tracks_t = df_tracks\n",
    "# Primero eliminaremos aquellas variables con muchas ausencias.\n",
    "df_tracks_t = df_tracks_t.drop(['decibel_range', 'second_artist'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación registros con ausencias\n",
    "#¿Porqué realizar este paso?\n",
    "df_tracks_t = df_tracks_t.dropna()\n",
    "# Eliminación de registros duplicados.\n",
    "df_tracks_t = df_tracks_t.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto es importante reflexionar en otra alternativa para no perder registros por celdas con valores nulos. ¿Cuándo tendrá sentido utilizar una estrategia distinta a eliminar los registros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks_t.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos y número de variables\n",
    "df_tracks_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante analizar el objetivo del modelo analítico a construir antes de iniciar a tomar decisiones. En este caso, por ejemplo, se debe aplicar la regla dada por el negocio, sobre qué significa una canción popular y que no, para generar la nueva variable que será la clase (variable objetivo).\n",
    "\n",
    "Esta nueva columna la derivaremos a partir de la variable \"popularity\" utilizando un umbral que nos permita determinar cuándo una canción es popular. Si el valor en esta variable es mayor que el umbral entonces ese registro se clasifica como \"popular\" y será indicado con un \"1\", de lo contrario será \"no popular y esta categoría la representaremos con un \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver los estadísticos de la variable \"popularity\"\n",
    "df_tracks_t['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El observar las variables de forma gráfica puede ayudar al negocio a decidir el punto a partir del cual se tienen canciones populares.\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "ax = sns.boxplot(\"popularity\", data=df_tracks_t, orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora definimos la función que nos va a permitir construir nuestra clase.\n",
    "def label_popularity (row):\n",
    "    if row['popularity'] > 33 :\n",
    "        return 1\n",
    "    return 0\n",
    "df_tracks_t['popularity_label']=df_tracks_t.apply (lambda row: label_popularity(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de datos de cada clase\n",
    "pd.value_counts(df_tracks_t['popularity_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='popularity_label', data=df_tracks_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos las variables que consideramos no son útiles para la tarea que queremos resolver, como los identificadores.\n",
    "df_tracks_t = df_tracks_t.drop(['id', 'id_artists'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspecto muy importante para tener en cuenta son los requerimientos de entrada de los algoritmos de aprendizaje implementados en las librerías utilizadas. En particular, scikit-learn requiere que todos los atributos sean numéricos y que la variable objetivo, en una tarea de clasificación, esté codificada con números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a seleccionar de nuestro conjunto solo los atributos numéricos.\n",
    "number_cols = df_tracks_t.dtypes[(df_tracks_t.dtypes == np.int64) | (df_tracks_t.dtypes == np.float64)].index \n",
    "number_cols = df_tracks_t.select_dtypes(include = ['int64','float']).columns\n",
    "number_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tracks_m = df_tracks_t[number_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver como quedaron los datos\n",
    "df_tracks_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión del total de registros\n",
    "df_tracks_m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, deben justificar las decisiones más importantes asociadas al proceso, tales como los criterios utilizados para la selección de hiperparámetros y las modificaciones a los datos para construir cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arboles de Decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, deben justificar las decisiones más importantes asociadas al proceso, tales como los criterios utilizados para la selección de hiperparámetros y las modificaciones a los datos para construir cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Libre Elección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, deben justificar las decisiones más importantes asociadas al proceso, tales como los criterios utilizados para la selección de hiperparámetros y las modificaciones a los datos para construir cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Resultados Obtenidos y Utilidad de los Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de modelos obtenidos y Recomendación"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
