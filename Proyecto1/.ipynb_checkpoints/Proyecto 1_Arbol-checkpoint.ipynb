{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nicolasortega/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lectura de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mensaje sentimiento    id\n",
       "0     im feeling rather rotten so im not very ambiti...     sadness     0\n",
       "1             im updating my blog because i feel shitty     sadness     1\n",
       "2     i never make her separate from me because i do...     sadness     2\n",
       "3     i left with my bouquet of red and yellow tulip...         joy     3\n",
       "4       i was feeling a little vain when i did this one     sadness     4\n",
       "...                                                 ...         ...   ...\n",
       "1995  i just keep feeling like someone is being unki...       anger  1995\n",
       "1996  im feeling a little cranky negative after this...       anger  1996\n",
       "1997  i feel that i am useful to my people and that ...         joy  1997\n",
       "1998  im feeling more comfortable with derby i feel ...         joy  1998\n",
       "1999  i feel all weird when i have to meet w people ...        fear  1999\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datos.csv',sep=';',header=None)\n",
    "df.columns = ['mensaje','sentimiento']\n",
    "# df[\"id\"] = range(0,len(df[\"mensaje\"]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Tokenizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de limpieza de texto, dentro del ámbito de text mining, consiste en eliminar del texto todo aquello que no aporte información sobre su temática, estructura o contenido. No existe una única forma de hacerlo, depende en gran medida de la finalidad del análisis y de la fuente de la que proceda el texto. Por ejemplo, en las redes sociales, los usuarios pueden escribir de la forma que quieran, lo que suele resultar en un uso elevado de abreviaturas y signos de puntuación. En este ejercicio, se procede a eliminar: patrones no informativos (urls de páginas web), signos de puntuación, etiquetas HTML, caracteres sueltos y números.\n",
    "\n",
    "Tokenizar un texto consiste en dividir el texto en las unidades que lo conforman, entendiendo por unidad el elemento más sencillo con significado propio para el análisis en cuestión, en este caso, las palabras.\n",
    "\n",
    "Existen múltiples librerías que automatizan en gran medida la limpieza y tokenización de texto, por ejemplo, la clase feature_extraction.text.CountVectorizer de Scikit Learn, nltk.tokenize o spaCy. A pesar de ello, para este ejemplo, se define una función que, si bien está menos optimizada, tiene la ventaja de poder adaptarse fácilmente dependiendo del tipo de texto analizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto es 1 ejemplo de l'limpieza de6 TEXTO  https://t.co/rnHPgyhx4Z @cienciadedatos #textmining\n",
      "['esto', 'es', 'ejemplo', 'de', 'limpieza', 'de', 'texto', 'cienciadedatos', 'textmining']\n"
     ]
    }
   ],
   "source": [
    "def limpiar_tokenizar(mensaje):\n",
    "    '''\n",
    "    Esta función limpia y tokeniza el texto en palabras individuales.\n",
    "    El orden en el que se va limpiando el texto no es arbitrario.\n",
    "    El listado de signos de puntuación se ha obtenido de: print(string.punctuation)\n",
    "    y re.escape(string.punctuation)\n",
    "    '''\n",
    "    \n",
    "    # Se convierte todo el texto a minúsculas\n",
    "    nuevo_texto = mensaje.lower()\n",
    "    # Eliminación de páginas web (palabras que empiezan por \"http\")\n",
    "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "    # Eliminación de signos de puntuación\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "    # Eliminación de números\n",
    "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "    # Eliminación de espacios en blanco múltiples\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    # Tokenización por palabras individuales\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    # Eliminación de tokens con una longitud < 2\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 1]\n",
    "    \n",
    "    return(nuevo_texto)\n",
    "\n",
    "test = \"Esto es 1 ejemplo de l'limpieza de6 TEXTO  https://t.co/rnHPgyhx4Z @cienciadedatos #textmining\"\n",
    "print(test)\n",
    "print(limpiar_tokenizar(mensaje=test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "      <th>mensaje_tokenizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, feeling, rather, rotten, so, im, not, ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, updating, my, blog, because, feel, shitty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2</td>\n",
       "      <td>[never, make, her, separate, from, me, because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "      <td>[left, with, my, bouquet, of, red, and, yellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>[was, feeling, little, vain, when, did, this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1995</td>\n",
       "      <td>[just, keep, feeling, like, someone, is, being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1996</td>\n",
       "      <td>[im, feeling, little, cranky, negative, after,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1997</td>\n",
       "      <td>[feel, that, am, useful, to, my, people, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1998</td>\n",
       "      <td>[im, feeling, more, comfortable, with, derby, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1999</td>\n",
       "      <td>[feel, all, weird, when, have, to, meet, peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mensaje sentimiento    id  \\\n",
       "0     im feeling rather rotten so im not very ambiti...     sadness     0   \n",
       "1             im updating my blog because i feel shitty     sadness     1   \n",
       "2     i never make her separate from me because i do...     sadness     2   \n",
       "3     i left with my bouquet of red and yellow tulip...         joy     3   \n",
       "4       i was feeling a little vain when i did this one     sadness     4   \n",
       "...                                                 ...         ...   ...   \n",
       "1995  i just keep feeling like someone is being unki...       anger  1995   \n",
       "1996  im feeling a little cranky negative after this...       anger  1996   \n",
       "1997  i feel that i am useful to my people and that ...         joy  1997   \n",
       "1998  im feeling more comfortable with derby i feel ...         joy  1998   \n",
       "1999  i feel all weird when i have to meet w people ...        fear  1999   \n",
       "\n",
       "                                     mensaje_tokenizado  \n",
       "0     [im, feeling, rather, rotten, so, im, not, ver...  \n",
       "1       [im, updating, my, blog, because, feel, shitty]  \n",
       "2     [never, make, her, separate, from, me, because...  \n",
       "3     [left, with, my, bouquet, of, red, and, yellow...  \n",
       "4     [was, feeling, little, vain, when, did, this, ...  \n",
       "...                                                 ...  \n",
       "1995  [just, keep, feeling, like, someone, is, being...  \n",
       "1996  [im, feeling, little, cranky, negative, after,...  \n",
       "1997  [feel, that, am, useful, to, my, people, and, ...  \n",
       "1998  [im, feeling, more, comfortable, with, derby, ...  \n",
       "1999  [feel, all, weird, when, have, to, meet, peopl...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se aplica la función de limpieza y tokenización a cada mensaje\n",
    "# ==============================================================================\n",
    "df['mensaje_tokenizado'] = df['mensaje'].apply(lambda x: limpiar_tokenizar(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entender que caracteriza la escritura de cada autor, es interesante estudiar qué palabras emplea, con qué frecuencia, así como el significado de las mismas.\n",
    "\n",
    "En Python, una de las estructuras que más facilita el análisis exploratorio es el DataFrame de Pandas, que es la estructura en la que se encuentra almacenada ahora la información de los tweets. Sin embargo, al realizar la tokenización, ha habido un cambio importante. Antes de dividir el texto, los elementos de estudio eran los tweets, y cada uno se encontraba en una fila, cumplimento así la condición de tidy data: una observación, una fila. Al realizar la tokenización, el elemento de estudio ha pasado a ser cada token (palabra), incumpliendo así la condición de tidy data. Para volver de nuevo a la estructura ideal se tiene que expandir cada lista de tokens, duplicando el valor de las otras columnas tantas veces como sea necesario. A este proceso se le conoce como expansión o unnest.\n",
    "\n",
    "Aunque puede parecer un proceso poco eficiente (el número de filas aumenta mucho), este simple cambio facilita actividades de tipo: agrupación, contaje, gráficos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>feeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>rather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimiento  id    token\n",
       "0     sadness   0       im\n",
       "0     sadness   0  feeling\n",
       "0     sadness   0   rather"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unnest de la columna texto_tokenizado\n",
    "# ==============================================================================\n",
    "df_tidy = df.explode(column='mensaje_tokenizado')\n",
    "df_tidy = df_tidy.drop(columns='mensaje')\n",
    "df_tidy = df_tidy.rename(columns={'mensaje_tokenizado':'token'})\n",
    "df_tidy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras totales utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34073"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy['token'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras totales distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy['token'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras más utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # df_tidy.groupby(['token'])[\"token\"] \\\n",
    " # .count() \\\n",
    " # .reset_index(name='count') \\\n",
    " # .apply(lambda x: x.sort_values('count', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tabla anterior puede observarse que los términos más frecuentes en todos los usuarios se corresponden con artículos, preposiciones, pronombres…, en general, palabras que no aportan información relevante sobre el texto. Ha estas palabras se les conoce como stopwords. Para cada idioma existen distintos listados de stopwords, además, dependiendo del contexto, puede ser necesario adaptar el listado. Por ejemplo, en la tabla anterior aparece el término amp que procede de la etiqueta html &amp. Con frecuencia, a medida que se realiza un análisis se encuentran palabras que deben incluirse en el listado de stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# Obtención de listado de stopwords del inglés\n",
    "# ==============================================================================\n",
    "stop_words = list(stopwords.words('english'))\n",
    "# Se añade la stoprword: amp, ax, ex\n",
    "stop_words.extend((\"amp\", \"xa\", \"xe\"))\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado para excluir stopwords\n",
    "# ==============================================================================\n",
    "df_tidy = df_tidy[~(df_tidy[\"token\"].isin(stop_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top 10 palabras (sin stopwords)\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1,figsize=(6, 7))\n",
    "counts  = df_tidy['token'].value_counts(ascending=False).head(10)\n",
    "counts.plot(kind='barh', color='firebrick')\n",
    "axs.invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency e Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los principales intereses en text mining, natural language processing e information retrieval es cuantificar la temática de un texto, así como la importancia de cada término que lo forma. Una manera sencilla de medir la importancia de un término dentro de un documento es utilizando la frecuencia con la que aparece (tf, term-frequency). Esta aproximación, aunque simple, tiene la limitación de atribuir mucha importancia a aquellas palabras que aparecen muchas veces aunque no aporten información selectiva. Por ejemplo, si la palabra matemáticas aparece 5 veces en un documento y la palabra página aparece 50, la segunda tendrá 10 veces más peso a pesar de que no aporte tanta información sobre la temática del documento. Para solucionar este problema se pueden ponderar los valores tf multiplicándolos por la inversa de la frecuencia con la que el término en cuestión aparece en el resto de documentos(idf). De esta forma, se consigue reducir el valor de aquellos términos que aparecen en muchos documentos y que, por lo tanto, no aportan información selectiva.\n",
    "\n",
    "El estadístico tf-idf mide cómo de informativo es un término en un documento teniendo en cuenta la frecuencia con la que ese término aparece en otros documentos.\n",
    "\n",
    "\n",
    "\n",
    "Term Frequency (tf)\n",
    "\n",
    "tf (t, d)=𝑛tlongitud d\n",
    " \n",
    "donde  𝑛t  es el número de veces que aparece el término  𝑡  en el documento  𝑑 .\n",
    "\n",
    "Inverse Document Frequency\n",
    "\n",
    "idf (t)=log(𝑛d𝑛(d,t))\n",
    " \n",
    "donde  𝑛d  es el número total de documentos y  𝑛(d,t)  el número de documentos que contienen el término  𝑡 .\n",
    "\n",
    "Estadístico tf-idf\n",
    "\n",
    "tf-idf(t, d)=tf (t, d)∗idf (t)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "En la práctica, para evitar problemas con el logaritmo cuando aparecen valores de 0, se emplea una versión corregida del  idf (t) . Esta es la versión implementada en Scikit Learn.\n",
    "\n",
    "idf (t)=log1+𝑛𝑑1+𝑛(d,t)+1\n",
    " \n",
    "\n",
    "\n",
    "En los siguientes apartados se muestra cómo calcular el valor tf-idf Sin embargo, en la práctica, es preferible utilizar implementaciones como TfidfVectorizer de Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>591</td>\n",
       "      <td>show</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>591</td>\n",
       "      <td>fears</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>591</td>\n",
       "      <td>feel</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  token  count  total_count        tf\n",
       "5231  591   show      1           31  0.032258\n",
       "5215  591  fears      1           31  0.032258\n",
       "5216  591   feel      1           31  0.032258"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo term-frecuency (tf)\n",
    "# ==============================================================================\n",
    "tf = df_tidy.copy()\n",
    "\n",
    "# Número de veces que aparece cada término en cada tweet\n",
    "tf = tf.groupby([\"id\",\"token\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "# Se añade una columna con el total de términos por tweet\n",
    "tf['total_count'] = tf.groupby('id')['count'].transform(sum)\n",
    "# Se calcula el tf\n",
    "tf['tf'] = tf[\"count\"] / tf[\"total_count\"]\n",
    "tf.sort_values(by = \"tf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>feel</td>\n",
       "      <td>1394</td>\n",
       "      <td>1.203399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>feeling</td>\n",
       "      <td>646</td>\n",
       "      <td>1.972532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>like</td>\n",
       "      <td>373</td>\n",
       "      <td>2.521753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  n_documentos       idf\n",
       "1515     feel          1394  1.203399\n",
       "1516  feeling           646  1.972532\n",
       "2371     like           373  2.521753"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse document frequency\n",
    "# ==============================================================================\n",
    "idf = df_tidy.copy()\n",
    "total_documents = idf[\"token\"].drop_duplicates().count()\n",
    "# Número de documentos (tweets) en los que aparece cada término\n",
    "idf = idf.groupby([\"token\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "idf['n_documentos'] = idf.groupby('token')['count'].transform(sum)\n",
    "# Cálculo del idf\n",
    "idf['idf'] = np.log(total_documents / idf['n_documentos'])\n",
    "idf = idf[[\"token\",\"n_documentos\", \"idf\"]].drop_duplicates()\n",
    "idf.sort_values(by=\"idf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>310</td>\n",
       "      <td>aaaah</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.443331</td>\n",
       "      <td>2.110833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>926</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.459045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15891</th>\n",
       "      <td>1083</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.816080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>884</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.432042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <td>434</td>\n",
       "      <td>abandoning</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.443331</td>\n",
       "      <td>1.055416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       token  count  total_count        tf  n_documentos       idf  \\\n",
       "12361   310       aaaah      1            4  0.250000             1  8.443331   \n",
       "15890   926   abandoned      1           16  0.062500             3  7.344719   \n",
       "15891  1083   abandoned      1            9  0.111111             3  7.344719   \n",
       "15889   884   abandoned      1           17  0.058824             3  7.344719   \n",
       "13502   434  abandoning      1            8  0.125000             1  8.443331   \n",
       "\n",
       "         tf_idf  \n",
       "12361  2.110833  \n",
       "15890  0.459045  \n",
       "15891  0.816080  \n",
       "15889  0.432042  \n",
       "13502  1.055416  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency - Inverse Document Frequency\n",
    "# ==============================================================================\n",
    "tf_idf = pd.merge(left=tf, right=idf, on=\"token\")\n",
    "tf_idf[\"tf_idf\"] = tf_idf[\"tf\"] * tf_idf[\"idf\"]\n",
    "tf_idf.sort_values(by=\"token\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede observarse que para el primer tweet (id = 1.195196e+17), todos los términos que aparecen una vez, tienen el mismo valor de tf, sin embargo, dado que no todos los términos aparecen con la misma frecuencia en el conjunto de todos los tweets, la corrección de idf es distinta para cada uno.\n",
    "\n",
    "De nuevo remarcar que, si bien se ha realizado el cálculo de forma manual con fines ilustrativos, en la práctica, es preferible utilizar implementaciones optimizadas como es el caso de la clase TfidfVectorizer de Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de mensajes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder aplicar algoritmos de clasificación a un texto, es necesario crear una representación numérica del mismo. Una de las formas más utilizadas se conoce como Bag of Words. Este método consiste en identificar el set formado por todas las palabras (tokens) que aparecen en el corpus, en este caso el conjunto de todos los tweets recuperados. Con este set se crea un espacio n-dimensional en el que cada dimensión (columna) es una palabra. Por último, se proyecta cada texto en ese espacio, asignando un valor para cada dimensión. En la mayoría de casos, el valor utilizado es el tf-idf.\n",
    "\n",
    "En el siguiente apartado se construye un modelo de aprendizaje estadístico basado en máquinas de vector soporte (SVM) con el objetivo de predecir la autoría de los tweets. En concreto, se comparan los tweets de Elon Musk y Mayor Ed Lee.\n",
    "\n",
    "Como modelo se emplea un SVM de Scikit-Learn. Para facilitar la obtención de la matriz TF-IDF se recurre a la clase TfidVectorized también de Scikit-Learn pero, en lugar de utilizar el tokenizador por defecto, se emplea el mismo definido en los apartados anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['mensaje']\n",
    "y = df['sentimiento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.2,\n",
    "                                        random_state = 123\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Empleando los tweets de entrenamiento se crea un matriz tf-idf en la que cada columna es un término, cada fila un documento y el valor de intersección el tf-idf correspondiente. Esta matriz representa el espacio n-dimensional en el que se proyecta cada tweet.\n",
    "\n",
    "La clase TfidfVectorizer de Scikit Learn automatizan la creación de una matriz df-idf a partir de un corpus de documentos. Entre sus argumentos destaca:\n",
    "\n",
    "encoding: el tipo de codificación del texto, por defecto es 'utf-8'.\n",
    "\n",
    "strip_accents: eliminación de acentos sustituyendolos por la misma letra sin el acento. Por defecto se emplea el método ‘ascii’.\n",
    "\n",
    "lowercase: convertir a minúsculas todo el texto.\n",
    "\n",
    "tokenizer: en caso de querer pasar un tokenizador definido por el usuario o de otra librería.\n",
    "\n",
    "analyzer: tipo de división que realiza el tokenizador. Por defecto separa por palabras ('word').\n",
    "\n",
    "stop_words: lista de stopwords que se eliminan durante el tokenizado. Por defecto utiliza un listado para el inglés.\n",
    "\n",
    "ngram_range: rango de n-gramas incluidos. Por ejemplo, (1, 2) significa que se incluyen unigramas (palabras individuales) y bigramas (pares de palabras) como tokens.\n",
    "\n",
    "min_df: fracción o número de documentos en los que debe de aparecer como mínimo un término para no ser excluido en el tokenizado. Este filtrado es una forma de eliminar ruido del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de la matriz tf-idf\n",
    "# ==============================================================================\n",
    "tfidf_vectorizador = TfidfVectorizer(\n",
    "#                         tokenizer  = limpiar_tokenizar,\n",
    "                        min_df     = 3,\n",
    "                        stop_words = stop_words,\n",
    "                        analyzer = \"word\"\n",
    "                    )\n",
    "X_vec = tfidf_vectorizador.fit_transform(X)\n",
    "# X = pd.DataFrame(X_vec.toarray(), columns=tfidf_vectorizador.get_feature_names())\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Número de tokens creados: 1257\n",
      "['abandoned', 'able', 'absolutely', 'accept', 'acceptable', 'accepted', 'accepting', 'aching', 'act', 'action']\n"
     ]
    }
   ],
   "source": [
    "print(f\" Número de tokens creados: {len(tfidf_vectorizador.get_feature_names())}\")\n",
    "print(tfidf_vectorizador.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizador.transform(X_train)\n",
    "tfidf_test  = tfidf_vectorizador.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión\n",
    "\n",
    "Primero, revisamos la distiribución de nuestra clase objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(len(X_vec.toarray()), df[\"sentimiento\"].count())\n",
    "ax = sns.countplot(x='sentimiento', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, existe un desbalanceo notable. La mayoría de registros se concentran en las emociones \"sadness\" y \"joy\".\n",
    "\n",
    "Intentaremos arreglar este problema de desbalanceo con la técnica de SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=0)\n",
    "\n",
    "# X_sm, y_sm = sm.fit_resample(X_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'''Shape of X before SMOTE: {X_vec.shape}\n",
    "# Hape of X after SMOTE: {X_sm.shape}\\n''')\n",
    "# ax = sns.countplot(x='sentimiento', data=pd.DataFrame(y_sm, columns=['sentimiento']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijemos el número de particiones. Utilizaremos K = 10.\n",
    "particiones = KFold(n_splits=10, shuffle=True, random_state = 0)\n",
    "\n",
    "# Establecemos el espacio de búsqueda para los hiperparámetros que deseamos ajustar. \n",
    "param_grid = {'criterion':['gini', 'entropy'],'max_depth':[4,8,12,20,24],'min_samples_split':range(2,10)}\n",
    "\n",
    "# Definimos el modelo sin ningún valor de estos hiperparámetros\n",
    "arbol = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 8, 12, 20, 24],\n",
       "                         'min_samples_split': range(2, 10)})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora utilizamos GridSearch sobre el grid definido y con 10 particiones en la validación cruzada.\n",
    "mejor_modelo = GridSearchCV(arbol, param_grid, cv=particiones)\n",
    "# Ajuste del modelo\n",
    "mejor_modelo.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver cuál fue el resultado de la búsqueda (mejores valores de hiperparámetros)\n",
    "mejor_modelo.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo.\n",
    "arbol_final = mejor_modelo.best_estimator_\n",
    "arbol_final = arbol_final.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el desempeño sobre el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbol_final = DecisionTreeClassifier(criterion=\"gini\", max_depth=12, min_samples_split=2)\n",
    "# arbol_final = arbol_final.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.52\n",
      "Recall: 0.5225\n",
      "Precisión: 0.7830785714285714\n",
      "Puntuación F1: 0.44271345425853753\n"
     ]
    }
   ],
   "source": [
    "y_pred = arbol_final.predict(tfidf_train)\n",
    "print('Exactitud: %.2f' % accuracy_score(y_train, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(y_train,y_pred, average=\"weighted\")))\n",
    "print(\"Precisión: {}\".format(precision_score(y_train,y_pred, average=\"weighted\")))\n",
    "print(\"Puntuación F1: {}\".format(f1_score(y_train,y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el desempeño sobre el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.37\n",
      "Recall: 0.366875\n",
      "Precisión: 0.6032554793199263\n",
      "Puntuación F1: 0.24538878799441777\n"
     ]
    }
   ],
   "source": [
    "y_pred = arbol_final.predict(tfidf_test)\n",
    "print('Exactitud: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(y_test,y_pred,average=\"weighted\")))\n",
    "print(\"Precisión: {}\".format(precision_score(y_test,y_pred,average=\"weighted\")))\n",
    "print(\"Puntuación F1: {}\".format(f1_score(y_test,y_pred,average=\"weighted\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
