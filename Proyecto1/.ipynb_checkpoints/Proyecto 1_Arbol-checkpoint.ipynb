{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /opt/anaconda3/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nicolasortega/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Gr√°ficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#style.use('ggplot') or plt.style.use('ggplot')\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Configuraci√≥n warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lectura de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mensaje sentimiento    id\n",
       "0     im feeling rather rotten so im not very ambiti...     sadness     0\n",
       "1             im updating my blog because i feel shitty     sadness     1\n",
       "2     i never make her separate from me because i do...     sadness     2\n",
       "3     i left with my bouquet of red and yellow tulip...         joy     3\n",
       "4       i was feeling a little vain when i did this one     sadness     4\n",
       "...                                                 ...         ...   ...\n",
       "1995  i just keep feeling like someone is being unki...       anger  1995\n",
       "1996  im feeling a little cranky negative after this...       anger  1996\n",
       "1997  i feel that i am useful to my people and that ...         joy  1997\n",
       "1998  im feeling more comfortable with derby i feel ...         joy  1998\n",
       "1999  i feel all weird when i have to meet w people ...        fear  1999\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datos.csv',sep=';',header=None)\n",
    "df.columns = ['mensaje','sentimiento']\n",
    "# df[\"id\"] = range(0,len(df[\"mensaje\"]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y Tokenizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de limpieza de texto, dentro del √°mbito de text mining, consiste en eliminar del texto todo aquello que no aporte informaci√≥n sobre su tem√°tica, estructura o contenido. No existe una √∫nica forma de hacerlo, depende en gran medida de la finalidad del an√°lisis y de la fuente de la que proceda el texto. Por ejemplo, en las redes sociales, los usuarios pueden escribir de la forma que quieran, lo que suele resultar en un uso elevado de abreviaturas y signos de puntuaci√≥n. En este ejercicio, se procede a eliminar: patrones no informativos (urls de p√°ginas web), signos de puntuaci√≥n, etiquetas HTML, caracteres sueltos y n√∫meros.\n",
    "\n",
    "Tokenizar un texto consiste en dividir el texto en las unidades que lo conforman, entendiendo por unidad el elemento m√°s sencillo con significado propio para el an√°lisis en cuesti√≥n, en este caso, las palabras.\n",
    "\n",
    "Existen m√∫ltiples librer√≠as que automatizan en gran medida la limpieza y tokenizaci√≥n de texto, por ejemplo, la clase feature_extraction.text.CountVectorizer de Scikit Learn, nltk.tokenize o spaCy. A pesar de ello, para este ejemplo, se define una funci√≥n que, si bien est√° menos optimizada, tiene la ventaja de poder adaptarse f√°cilmente dependiendo del tipo de texto analizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esto es 1 ejemplo de l'limpieza de6 TEXTO  https://t.co/rnHPgyhx4Z @cienciadedatos #textmining\n",
      "['esto', 'es', 'ejemplo', 'de', 'limpieza', 'de', 'texto', 'cienciadedatos', 'textmining']\n"
     ]
    }
   ],
   "source": [
    "def limpiar_tokenizar(mensaje):\n",
    "    '''\n",
    "    Esta funci√≥n limpia y tokeniza el texto en palabras individuales.\n",
    "    El orden en el que se va limpiando el texto no es arbitrario.\n",
    "    El listado de signos de puntuaci√≥n se ha obtenido de: print(string.punctuation)\n",
    "    y re.escape(string.punctuation)\n",
    "    '''\n",
    "    \n",
    "    # Se convierte todo el texto a min√∫sculas\n",
    "    nuevo_texto = mensaje.lower()\n",
    "    # Eliminaci√≥n de p√°ginas web (palabras que empiezan por \"http\")\n",
    "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "    # Eliminaci√≥n de signos de puntuaci√≥n\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "    # Eliminaci√≥n de n√∫meros\n",
    "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "    # Eliminaci√≥n de espacios en blanco m√∫ltiples\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    # Tokenizaci√≥n por palabras individuales\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    # Eliminaci√≥n de tokens con una longitud < 2\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 1]\n",
    "    \n",
    "    return(nuevo_texto)\n",
    "\n",
    "test = \"Esto es 1 ejemplo de l'limpieza de6 TEXTO  https://t.co/rnHPgyhx4Z @cienciadedatos #textmining\"\n",
    "print(test)\n",
    "print(limpiar_tokenizar(mensaje=test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mensaje</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "      <th>mensaje_tokenizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, feeling, rather, rotten, so, im, not, ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, updating, my, blog, because, feel, shitty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>2</td>\n",
       "      <td>[never, make, her, separate, from, me, because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "      <td>[left, with, my, bouquet, of, red, and, yellow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "      <td>[was, feeling, little, vain, when, did, this, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1995</td>\n",
       "      <td>[just, keep, feeling, like, someone, is, being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "      <td>1996</td>\n",
       "      <td>[im, feeling, little, cranky, negative, after,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1997</td>\n",
       "      <td>[feel, that, am, useful, to, my, people, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>1998</td>\n",
       "      <td>[im, feeling, more, comfortable, with, derby, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>1999</td>\n",
       "      <td>[feel, all, weird, when, have, to, meet, peopl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mensaje sentimiento    id  \\\n",
       "0     im feeling rather rotten so im not very ambiti...     sadness     0   \n",
       "1             im updating my blog because i feel shitty     sadness     1   \n",
       "2     i never make her separate from me because i do...     sadness     2   \n",
       "3     i left with my bouquet of red and yellow tulip...         joy     3   \n",
       "4       i was feeling a little vain when i did this one     sadness     4   \n",
       "...                                                 ...         ...   ...   \n",
       "1995  i just keep feeling like someone is being unki...       anger  1995   \n",
       "1996  im feeling a little cranky negative after this...       anger  1996   \n",
       "1997  i feel that i am useful to my people and that ...         joy  1997   \n",
       "1998  im feeling more comfortable with derby i feel ...         joy  1998   \n",
       "1999  i feel all weird when i have to meet w people ...        fear  1999   \n",
       "\n",
       "                                     mensaje_tokenizado  \n",
       "0     [im, feeling, rather, rotten, so, im, not, ver...  \n",
       "1       [im, updating, my, blog, because, feel, shitty]  \n",
       "2     [never, make, her, separate, from, me, because...  \n",
       "3     [left, with, my, bouquet, of, red, and, yellow...  \n",
       "4     [was, feeling, little, vain, when, did, this, ...  \n",
       "...                                                 ...  \n",
       "1995  [just, keep, feeling, like, someone, is, being...  \n",
       "1996  [im, feeling, little, cranky, negative, after,...  \n",
       "1997  [feel, that, am, useful, to, my, people, and, ...  \n",
       "1998  [im, feeling, more, comfortable, with, derby, ...  \n",
       "1999  [feel, all, weird, when, have, to, meet, peopl...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se aplica la funci√≥n de limpieza y tokenizaci√≥n a cada mensaje\n",
    "# ==============================================================================\n",
    "df['mensaje_tokenizado'] = df['mensaje'].apply(lambda x: limpiar_tokenizar(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## An√°lisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entender que caracteriza la escritura de cada autor, es interesante estudiar qu√© palabras emplea, con qu√© frecuencia, as√≠ como el significado de las mismas.\n",
    "\n",
    "En Python, una de las estructuras que m√°s facilita el an√°lisis exploratorio es el DataFrame de Pandas, que es la estructura en la que se encuentra almacenada ahora la informaci√≥n de los tweets. Sin embargo, al realizar la tokenizaci√≥n, ha habido un cambio importante. Antes de dividir el texto, los elementos de estudio eran los tweets, y cada uno se encontraba en una fila, cumplimento as√≠ la condici√≥n de tidy data: una observaci√≥n, una fila. Al realizar la tokenizaci√≥n, el elemento de estudio ha pasado a ser cada token (palabra), incumpliendo as√≠ la condici√≥n de tidy data. Para volver de nuevo a la estructura ideal se tiene que expandir cada lista de tokens, duplicando el valor de las otras columnas tantas veces como sea necesario. A este proceso se le conoce como expansi√≥n o unnest.\n",
    "\n",
    "Aunque puede parecer un proceso poco eficiente (el n√∫mero de filas aumenta mucho), este simple cambio facilita actividades de tipo: agrupaci√≥n, contaje, gr√°ficos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>feeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "      <td>rather</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentimiento  id    token\n",
       "0     sadness   0       im\n",
       "0     sadness   0  feeling\n",
       "0     sadness   0   rather"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unnest de la columna texto_tokenizado\n",
    "# ==============================================================================\n",
    "df_tidy = df.explode(column='mensaje_tokenizado')\n",
    "df_tidy = df_tidy.drop(columns='mensaje')\n",
    "df_tidy = df_tidy.rename(columns={'mensaje_tokenizado':'token'})\n",
    "df_tidy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras totales utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34073"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy['token'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras totales distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tidy['token'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras m√°s utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " # df_tidy.groupby(['token'])[\"token\"] \\\n",
    " # .count() \\\n",
    " # .reset_index(name='count') \\\n",
    " # .apply(lambda x: x.sort_values('count', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tabla anterior puede observarse que los t√©rminos m√°s frecuentes en todos los usuarios se corresponden con art√≠culos, preposiciones, pronombres‚Ä¶, en general, palabras que no aportan informaci√≥n relevante sobre el texto. Ha estas palabras se les conoce como stopwords. Para cada idioma existen distintos listados de stopwords, adem√°s, dependiendo del contexto, puede ser necesario adaptar el listado. Por ejemplo, en la tabla anterior aparece el t√©rmino amp que procede de la etiqueta html &amp. Con frecuencia, a medida que se realiza un an√°lisis se encuentran palabras que deben incluirse en el listado de stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "# Obtenci√≥n de listado de stopwords del ingl√©s\n",
    "# ==============================================================================\n",
    "stop_words = list(stopwords.words('english'))\n",
    "# Se a√±ade la stoprword: amp, ax, ex\n",
    "stop_words.extend((\"amp\", \"xa\", \"xe\"))\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado para excluir stopwords\n",
    "# ==============================================================================\n",
    "df_tidy = df_tidy[~(df_tidy[\"token\"].isin(stop_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top 10 palabras (sin stopwords)\n",
    "# ==============================================================================\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1,figsize=(6, 7))\n",
    "counts  = df_tidy['token'].value_counts(ascending=False).head(10)\n",
    "counts.plot(kind='barh', color='firebrick')\n",
    "axs.invert_yaxis()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency e Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los principales intereses en text mining, natural language processing e information retrieval es cuantificar la tem√°tica de un texto, as√≠ como la importancia de cada t√©rmino que lo forma. Una manera sencilla de medir la importancia de un t√©rmino dentro de un documento es utilizando la frecuencia con la que aparece (tf, term-frequency). Esta aproximaci√≥n, aunque simple, tiene la limitaci√≥n de atribuir mucha importancia a aquellas palabras que aparecen muchas veces aunque no aporten informaci√≥n selectiva. Por ejemplo, si la palabra matem√°ticas aparece 5 veces en un documento y la palabra p√°gina aparece 50, la segunda tendr√° 10 veces m√°s peso a pesar de que no aporte tanta informaci√≥n sobre la tem√°tica del documento. Para solucionar este problema se pueden ponderar los valores tf multiplic√°ndolos por la inversa de la frecuencia con la que el t√©rmino en cuesti√≥n aparece en el resto de documentos(idf). De esta forma, se consigue reducir el valor de aquellos t√©rminos que aparecen en muchos documentos y que, por lo tanto, no aportan informaci√≥n selectiva.\n",
    "\n",
    "El estad√≠stico tf-idf mide c√≥mo de informativo es un t√©rmino en un documento teniendo en cuenta la frecuencia con la que ese t√©rmino aparece en otros documentos.\n",
    "\n",
    "\n",
    "\n",
    "Term Frequency (tf)\n",
    "\n",
    "tf (t, d)=ùëõtlongitud d\n",
    " \n",
    "donde  ùëõt  es el n√∫mero de veces que aparece el t√©rmino  ùë°  en el documento  ùëë .\n",
    "\n",
    "Inverse Document Frequency\n",
    "\n",
    "idf (t)=log(ùëõdùëõ(d,t))\n",
    " \n",
    "donde  ùëõd  es el n√∫mero total de documentos y  ùëõ(d,t)  el n√∫mero de documentos que contienen el t√©rmino  ùë° .\n",
    "\n",
    "Estad√≠stico tf-idf\n",
    "\n",
    "tf-idf(t, d)=tf (t, d)‚àóidf (t)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "En la pr√°ctica, para evitar problemas con el logaritmo cuando aparecen valores de 0, se emplea una versi√≥n corregida del  idf (t) . Esta es la versi√≥n implementada en Scikit Learn.\n",
    "\n",
    "idf (t)=log1+ùëõùëë1+ùëõ(d,t)+1\n",
    " \n",
    "\n",
    "\n",
    "En los siguientes apartados se muestra c√≥mo calcular el valor tf-idf Sin embargo, en la pr√°ctica, es preferible utilizar implementaciones como TfidfVectorizer de Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5231</th>\n",
       "      <td>591</td>\n",
       "      <td>show</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>591</td>\n",
       "      <td>fears</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>591</td>\n",
       "      <td>feel</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  token  count  total_count        tf\n",
       "5231  591   show      1           31  0.032258\n",
       "5215  591  fears      1           31  0.032258\n",
       "5216  591   feel      1           31  0.032258"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C√°lculo term-frecuency (tf)\n",
    "# ==============================================================================\n",
    "tf = df_tidy.copy()\n",
    "\n",
    "# N√∫mero de veces que aparece cada t√©rmino en cada tweet\n",
    "tf = tf.groupby([\"id\",\"token\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "# Se a√±ade una columna con el total de t√©rminos por tweet\n",
    "tf['total_count'] = tf.groupby('id')['count'].transform(sum)\n",
    "# Se calcula el tf\n",
    "tf['tf'] = tf[\"count\"] / tf[\"total_count\"]\n",
    "tf.sort_values(by = \"tf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>feel</td>\n",
       "      <td>1394</td>\n",
       "      <td>1.203399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>feeling</td>\n",
       "      <td>646</td>\n",
       "      <td>1.972532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>like</td>\n",
       "      <td>373</td>\n",
       "      <td>2.521753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  n_documentos       idf\n",
       "1515     feel          1394  1.203399\n",
       "1516  feeling           646  1.972532\n",
       "2371     like           373  2.521753"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse document frequency\n",
    "# ==============================================================================\n",
    "idf = df_tidy.copy()\n",
    "total_documents = idf[\"token\"].drop_duplicates().count()\n",
    "# N√∫mero de documentos (tweets) en los que aparece cada t√©rmino\n",
    "idf = idf.groupby([\"token\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "idf['n_documentos'] = idf.groupby('token')['count'].transform(sum)\n",
    "# C√°lculo del idf\n",
    "idf['idf'] = np.log(total_documents / idf['n_documentos'])\n",
    "idf = idf[[\"token\",\"n_documentos\", \"idf\"]].drop_duplicates()\n",
    "idf.sort_values(by=\"idf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12361</th>\n",
       "      <td>310</td>\n",
       "      <td>aaaah</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.443331</td>\n",
       "      <td>2.110833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>926</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.459045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15891</th>\n",
       "      <td>1083</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.816080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>884</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>3</td>\n",
       "      <td>7.344719</td>\n",
       "      <td>0.432042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <td>434</td>\n",
       "      <td>abandoning</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.443331</td>\n",
       "      <td>1.055416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       token  count  total_count        tf  n_documentos       idf  \\\n",
       "12361   310       aaaah      1            4  0.250000             1  8.443331   \n",
       "15890   926   abandoned      1           16  0.062500             3  7.344719   \n",
       "15891  1083   abandoned      1            9  0.111111             3  7.344719   \n",
       "15889   884   abandoned      1           17  0.058824             3  7.344719   \n",
       "13502   434  abandoning      1            8  0.125000             1  8.443331   \n",
       "\n",
       "         tf_idf  \n",
       "12361  2.110833  \n",
       "15890  0.459045  \n",
       "15891  0.816080  \n",
       "15889  0.432042  \n",
       "13502  1.055416  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency - Inverse Document Frequency\n",
    "# ==============================================================================\n",
    "tf_idf = pd.merge(left=tf, right=idf, on=\"token\")\n",
    "tf_idf[\"tf_idf\"] = tf_idf[\"tf\"] * tf_idf[\"idf\"]\n",
    "tf_idf.sort_values(by=\"token\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede observarse que para el primer tweet (id = 1.195196e+17), todos los t√©rminos que aparecen una vez, tienen el mismo valor de tf, sin embargo, dado que no todos los t√©rminos aparecen con la misma frecuencia en el conjunto de todos los tweets, la correcci√≥n de idf es distinta para cada uno.\n",
    "\n",
    "De nuevo remarcar que, si bien se ha realizado el c√°lculo de forma manual con fines ilustrativos, en la pr√°ctica, es preferible utilizar implementaciones optimizadas como es el caso de la clase TfidfVectorizer de Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificaci√≥n de mensajes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder aplicar algoritmos de clasificaci√≥n a un texto, es necesario crear una representaci√≥n num√©rica del mismo. Una de las formas m√°s utilizadas se conoce como Bag of Words. Este m√©todo consiste en identificar el set formado por todas las palabras (tokens) que aparecen en el corpus, en este caso el conjunto de todos los tweets recuperados. Con este set se crea un espacio n-dimensional en el que cada dimensi√≥n (columna) es una palabra. Por √∫ltimo, se proyecta cada texto en ese espacio, asignando un valor para cada dimensi√≥n. En la mayor√≠a de casos, el valor utilizado es el tf-idf.\n",
    "\n",
    "En el siguiente apartado se construye un modelo de aprendizaje estad√≠stico basado en m√°quinas de vector soporte (SVM) con el objetivo de predecir la autor√≠a de los tweets. En concreto, se comparan los tweets de Elon Musk y Mayor Ed Lee.\n",
    "\n",
    "Como modelo se emplea un SVM de Scikit-Learn. Para facilitar la obtenci√≥n de la matriz TF-IDF se recurre a la clase TfidVectorized tambi√©n de Scikit-Learn pero, en lugar de utilizar el tokenizador por defecto, se emplea el mismo definido en los apartados anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['mensaje']\n",
    "y = df['sentimiento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y,\n",
    "                                        train_size   = 0.2,\n",
    "                                        random_state = 123\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizaci√≥n tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Empleando los tweets de entrenamiento se crea un matriz tf-idf en la que cada columna es un t√©rmino, cada fila un documento y el valor de intersecci√≥n el tf-idf correspondiente. Esta matriz representa el espacio n-dimensional en el que se proyecta cada tweet.\n",
    "\n",
    "La clase TfidfVectorizer de Scikit Learn automatizan la creaci√≥n de una matriz df-idf a partir de un corpus de documentos. Entre sus argumentos destaca:\n",
    "\n",
    "encoding: el tipo de codificaci√≥n del texto, por defecto es 'utf-8'.\n",
    "\n",
    "strip_accents: eliminaci√≥n de acentos sustituyendolos por la misma letra sin el acento. Por defecto se emplea el m√©todo ‚Äòascii‚Äô.\n",
    "\n",
    "lowercase: convertir a min√∫sculas todo el texto.\n",
    "\n",
    "tokenizer: en caso de querer pasar un tokenizador definido por el usuario o de otra librer√≠a.\n",
    "\n",
    "analyzer: tipo de divisi√≥n que realiza el tokenizador. Por defecto separa por palabras ('word').\n",
    "\n",
    "stop_words: lista de stopwords que se eliminan durante el tokenizado. Por defecto utiliza un listado para el ingl√©s.\n",
    "\n",
    "ngram_range: rango de n-gramas incluidos. Por ejemplo, (1, 2) significa que se incluyen unigramas (palabras individuales) y bigramas (pares de palabras) como tokens.\n",
    "\n",
    "min_df: fracci√≥n o n√∫mero de documentos en los que debe de aparecer como m√≠nimo un t√©rmino para no ser excluido en el tokenizado. Este filtrado es una forma de eliminar ruido del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaci√≥n de la matriz tf-idf\n",
    "# ==============================================================================\n",
    "tfidf_vectorizador = TfidfVectorizer(\n",
    "#                         tokenizer  = limpiar_tokenizar,\n",
    "                        min_df     = 3,\n",
    "                        stop_words = stop_words,\n",
    "                        analyzer = \"word\"\n",
    "                    )\n",
    "X_vec = tfidf_vectorizador.fit_transform(X)\n",
    "# X = pd.DataFrame(X_vec.toarray(), columns=tfidf_vectorizador.get_feature_names())\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " N√∫mero de tokens creados: 1257\n",
      "['abandoned', 'able', 'absolutely', 'accept', 'acceptable', 'accepted', 'accepting', 'aching', 'act', 'action']\n"
     ]
    }
   ],
   "source": [
    "print(f\" N√∫mero de tokens creados: {len(tfidf_vectorizador.get_feature_names())}\")\n",
    "print(tfidf_vectorizador.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizador.transform(X_train)\n",
    "tfidf_test  = tfidf_vectorizador.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √Årbol de decisi√≥n\n",
    "\n",
    "Primero, revisamos la distiribuci√≥n de nuestra clase objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(len(X_vec.toarray()), df[\"sentimiento\"].count())\n",
    "ax = sns.countplot(x='sentimiento', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, existe un desbalanceo notable. La mayor√≠a de registros se concentran en las emociones \"sadness\" y \"joy\".\n",
    "\n",
    "Intentaremos arreglar este problema de desbalanceo con la t√©cnica de SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=0)\n",
    "\n",
    "# X_sm, y_sm = sm.fit_resample(X_vec,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'''Shape of X before SMOTE: {X_vec.shape}\n",
    "# Hape of X after SMOTE: {X_sm.shape}\\n''')\n",
    "# ax = sns.countplot(x='sentimiento', data=pd.DataFrame(y_sm, columns=['sentimiento']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B√∫squeda de hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijemos el n√∫mero de particiones. Utilizaremos K = 10.\n",
    "particiones = KFold(n_splits=10, shuffle=True, random_state = 0)\n",
    "\n",
    "# Establecemos el espacio de b√∫squeda para los hiperpar√°metros que deseamos ajustar. \n",
    "param_grid = {'criterion':['gini', 'entropy'],'max_depth':[4,8,12,20,24],'min_samples_split':range(2,10)}\n",
    "\n",
    "# Definimos el modelo sin ning√∫n valor de estos hiperpar√°metros\n",
    "arbol = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "             estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 8, 12, 20, 24],\n",
       "                         'min_samples_split': range(2, 10)})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora utilizamos GridSearch sobre el grid definido y con 10 particiones en la validaci√≥n cruzada.\n",
    "mejor_modelo = GridSearchCV(arbol, param_grid, cv=particiones)\n",
    "# Ajuste del modelo\n",
    "mejor_modelo.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ver cu√°l fue el resultado de la b√∫squeda (mejores valores de hiperpar√°metros)\n",
    "mejor_modelo.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo.\n",
    "arbol_final = mejor_modelo.best_estimator_\n",
    "arbol_final = arbol_final.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el desempe√±o sobre el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbol_final = DecisionTreeClassifier(criterion=\"gini\", max_depth=12, min_samples_split=2)\n",
    "# arbol_final = arbol_final.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.52\n",
      "Recall: 0.5225\n",
      "Precisi√≥n: 0.7830785714285714\n",
      "Puntuaci√≥n F1: 0.44271345425853753\n"
     ]
    }
   ],
   "source": [
    "y_pred = arbol_final.predict(tfidf_train)\n",
    "print('Exactitud: %.2f' % accuracy_score(y_train, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(y_train,y_pred, average=\"weighted\")))\n",
    "print(\"Precisi√≥n: {}\".format(precision_score(y_train,y_pred, average=\"weighted\")))\n",
    "print(\"Puntuaci√≥n F1: {}\".format(f1_score(y_train,y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el desempe√±o sobre el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.37\n",
      "Recall: 0.366875\n",
      "Precisi√≥n: 0.6032554793199263\n",
      "Puntuaci√≥n F1: 0.24538878799441777\n"
     ]
    }
   ],
   "source": [
    "y_pred = arbol_final.predict(tfidf_test)\n",
    "print('Exactitud: %.2f' % accuracy_score(y_test, y_pred))\n",
    "print(\"Recall: {}\".format(recall_score(y_test,y_pred,average=\"weighted\")))\n",
    "print(\"Precisi√≥n: {}\".format(precision_score(y_test,y_pred,average=\"weighted\")))\n",
    "print(\"Puntuaci√≥n F1: {}\".format(f1_score(y_test,y_pred,average=\"weighted\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
